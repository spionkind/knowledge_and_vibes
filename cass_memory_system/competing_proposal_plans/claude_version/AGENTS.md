# AGENTS.md - cass-reflect Integration Guide

> This file teaches AI coding agents how to use `cass-reflect` for memory and reflection.

## Overview

`cass-reflect` is your memory system. It:
1. Searches your past sessions across ALL agents (Claude, Codex, Cursor, Aider, etc.)
2. Maintains a "playbook" of reusable coding wisdom
3. Tracks which rules help vs. cause problems

**Always use `--json` output for parsing.**

## Quick Reference

```bash
# Before starting a task - get relevant context
cass-reflect context "your task description" --json

# After using a playbook bullet successfully
cass-reflect mark <bullet-id> --helpful

# When a playbook bullet caused problems
cass-reflect mark <bullet-id> --harmful

# List available bullets
cass-reflect playbook list --json

# Search past sessions (via cass)
cass search "error pattern" --robot --limit 5
```

## Workflow Integration

### At Task Start

Before diving into complex tasks, retrieve context:

```bash
CONTEXT=$(cass-reflect context "Fix the authentication timeout in login.ts" --json)
```

The response includes:
- `bullets`: Relevant playbook entries with IDs
- `history`: Snippets from past sessions that solved similar problems
- `prompt`: Pre-formatted context to include in your reasoning

### During Task Execution

When you apply a playbook bullet:

```bash
# If it helped solve the problem
cass-reflect mark b-abc123 --helpful --session "$CURRENT_SESSION"

# If it led you astray or caused issues
cass-reflect mark b-abc123 --harmful --session "$CURRENT_SESSION"
```

### After Task Completion

For significant sessions, generate a diary entry:

```bash
cass-reflect diary "$SESSION_PATH" --json
```

This captures:
- What was accomplished
- Key decisions made
- Challenges encountered
- User preferences revealed

## Playbook Bullet Format

Bullets in the response look like:

```json
{
  "id": "b-1a2b3c4d",
  "category": "debugging",
  "content": "For TypeScript generic errors, check the instantiated type at call site",
  "helpful_count": 8,
  "harmful_count": 1,
  "tags": ["typescript", "debugging"]
}
```

**When referencing bullets in your work:**
- Cite the ID: "Following [b-1a2b3c4d], I'll check the instantiated type..."
- Mark usage after: helpful if it worked, harmful if it misled

## Adding New Learnings

When you discover something reusable:

```bash
cass-reflect playbook add \
  --category "testing" \
  --tags "jest,async" \
  "Wrap async act() calls in try/finally to ensure cleanup runs"
```

Guidelines for good bullets:
- **Be specific**: Not "write tests" but "For React async effects, use waitFor() not act()"
- **Include context**: When does this apply? What triggers it?
- **Cite evidence**: What error/situation revealed this?

## Error Handling

| Exit Code | Meaning | Action |
|-----------|---------|--------|
| 0 | Success | Parse stdout as JSON |
| 1 | General error | Check stderr for message |
| 2 | Config missing | Run `cass-reflect init` |

## Environment Requirements

- `cass` must be installed and in PATH
- One of: `ANTHROPIC_API_KEY`, `OPENAI_API_KEY`, `GOOGLE_GENERATIVE_AI_API_KEY`

## Example Integration

```python
import subprocess
import json

def get_task_context(task: str) -> dict:
    """Get relevant playbook entries and history for a task."""
    result = subprocess.run(
        ["cass-reflect", "context", task, "--json"],
        capture_output=True, text=True
    )
    if result.returncode != 0:
        return {"bullets": [], "history": [], "prompt": ""}
    return json.loads(result.stdout)

def mark_bullet(bullet_id: str, helpful: bool, session_path: str = None):
    """Track bullet usage."""
    cmd = ["cass-reflect", "mark", bullet_id]
    cmd.append("--helpful" if helpful else "--harmful")
    if session_path:
        cmd.extend(["--session", session_path])
    subprocess.run(cmd)

def search_history(query: str, limit: int = 5) -> list:
    """Search past sessions via cass."""
    result = subprocess.run(
        ["cass", "search", query, "--robot", "--limit", str(limit)],
        capture_output=True, text=True
    )
    if result.returncode != 0:
        return []
    return json.loads(result.stdout).get("hits", [])
```

## Best Practices

1. **Always check context first** for non-trivial tasks
2. **Mark bullets honestly** - harmful marks improve the system
3. **Be specific** when adding bullets - generic rules don't help
4. **Search history** when stuck - someone probably solved this before
5. **Generate diaries** for significant sessions to capture learnings
