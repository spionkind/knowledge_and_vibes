# D4C (Aligning the Objective of LLM‑Based Program Repair)

**Paper:** Aligning the Objective of LLM‑based Program Repair  
**URL:** https://arxiv.org/abs/2404.08877  
**Date:** Apr 2024  
**Venue:** arXiv preprint (ICSE 2025)

---

## Summary

D4C argues that many LLM-based program-repair pipelines fight the model’s training objective by:
- forcing “fill the buggy hunk” infilling formats
- depending heavily on perfect fault localization

Instead, D4C uses **direct debugging**: have the model refine the whole function/program using failure artifacts (tests/errors), which better matches next-token prediction.

---

## Key Results (Reported)

On Defects4J:
- **180** bugs repaired
- with only **10 samples per bug**
- surpasses prior SOTA APR methods that assume perfect fault localization by ~**10%**
- reduces sampling needs by ~**90%** vs some baselines

---

## Practical Implications (For Knowledge & Vibes)

1. **When localization is uncertain, allow bigger edits.** If you can’t confidently isolate the bug, a “rewrite the function” approach can outperform tiny patches.
2. **But keep it bounded.** In repo-scale work, prefer “rewrite the smallest correct locus” (function/module), not whole-repo rewrites.
3. **Repair beads should choose an edit strategy.** Add a decision: “surgical patch” vs “bounded rewrite,” based on evidence.

---

## Caveats

- Over-applying “rewrite” can increase merge conflicts and regressions; use tests and version control discipline.

